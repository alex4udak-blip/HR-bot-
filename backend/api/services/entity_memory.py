"""
Entity Long-term Memory Service

Provides AI memory persistence for entities:
- Auto-summarization of all interactions
- Key events extraction and tracking
- Context building for AI that preserves history without token overflow

The summary is updated periodically (not on every message) to save API costs.
"""
import logging
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
import anthropic

from ..config import get_settings

logger = logging.getLogger("hr-analyzer.entity-memory")
settings = get_settings()

# Update summary if older than this
SUMMARY_UPDATE_INTERVAL = timedelta(hours=24)

# Minimum new content to trigger summary update
MIN_NEW_CONTENT_LENGTH = 500


SUMMARY_PROMPT = """Ğ¢Ñ‹ â€” AI-Ğ°ÑÑĞ¸ÑÑ‚ĞµĞ½Ñ‚ Ğ´Ğ»Ñ HR. ĞĞ±Ğ½Ğ¾Ğ²Ğ¸ ĞºÑ€Ğ°Ñ‚ĞºĞ¾Ğµ Ñ€ĞµĞ·ÑĞ¼Ğµ Ğ¾ ĞºĞ¾Ğ½Ñ‚Ğ°ĞºÑ‚Ğµ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ’Ğ¡Ğ•Ğ™ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ¾Ğ¹ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸.

Ğ¢Ğ•ĞšĞ£Ğ©Ğ•Ğ• Ğ Ğ•Ğ—Ğ®ĞœĞ• (ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ):
{current_summary}

ĞĞĞ’Ğ«Ğ• Ğ”ĞĞĞĞ«Ğ•:
{new_content}

ĞšĞ›Ğ®Ğ§Ğ•Ğ’Ğ«Ğ• Ğ¡ĞĞ‘Ğ«Ğ¢Ğ˜Ğ¯ (ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ):
{key_events}

---

ĞĞ°Ğ¿Ğ¸ÑˆĞ¸ ĞĞ‘ĞĞĞ’Ğ›ĞĞĞĞĞ• Ñ€ĞµĞ·ÑĞ¼Ğµ (2-4 Ğ°Ğ±Ğ·Ğ°Ñ†Ğ°), ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ¾Ğµ Ğ²ĞºĞ»ÑÑ‡Ğ°ĞµÑ‚:
1. ĞšÑ‚Ğ¾ ÑÑ‚Ğ¾Ñ‚ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµĞº (Ñ€Ğ¾Ğ»ÑŒ, ĞºĞ¾Ğ¼Ğ¿Ğ°Ğ½Ğ¸Ñ, Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ñ)
2. Ğ˜ÑÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ (ĞºĞ°Ğº Ğ¿Ñ€Ğ¸ÑˆÑ‘Ğ», Ñ‡Ñ‚Ğ¾ Ğ¿Ñ€Ğ¾Ğ¸ÑÑ…Ğ¾Ğ´Ğ¸Ğ»Ğ¾)
3. ĞšĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ Ğ´Ğ¾ÑÑ‚Ğ¸Ğ¶ĞµĞ½Ğ¸Ñ Ğ¸Ğ»Ğ¸ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹
4. Ğ¢ĞµĞºÑƒÑ‰Ğ¸Ğ¹ ÑÑ‚Ğ°Ñ‚ÑƒÑ Ğ¾Ñ‚Ğ½Ğ¾ÑˆĞµĞ½Ğ¸Ğ¹
5. Ğ§Ñ‚Ğ¾ Ğ²Ğ°Ğ¶Ğ½Ğ¾ Ğ¿Ğ¾Ğ¼Ğ½Ğ¸Ñ‚ÑŒ Ğ´Ğ»Ñ Ğ±ÑƒĞ´ÑƒÑ‰Ğ¸Ñ… Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğ¹

ĞŸĞ¸ÑˆĞ¸ ĞºÑ€Ğ°Ñ‚ĞºĞ¾, Ğ½Ğ¾ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¾. Ğ¤Ğ¾ĞºÑƒÑĞ¸Ñ€ÑƒĞ¹ÑÑ Ğ½Ğ° Ñ„Ğ°ĞºÑ‚Ğ°Ñ…, Ğ° Ğ½Ğµ ÑĞ¼Ğ¾Ñ†Ğ¸ÑÑ….
ĞĞ• Ñ‚ĞµÑ€ÑĞ¹ Ğ²Ğ°Ğ¶Ğ½ÑƒÑ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¸Ğ· Ğ¿Ñ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰ĞµĞ³Ğ¾ Ñ€ĞµĞ·ÑĞ¼Ğµ!"""


KEY_EVENTS_PROMPT = """Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ¸ ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ ÑĞ¾Ğ±Ñ‹Ñ‚Ğ¸Ñ/Ğ²ĞµÑ…Ğ¸ Ğ¸Ğ· ÑÑ‚Ğ¾Ğ³Ğ¾ ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚Ğ°.

ĞšĞĞĞ¢Ğ•ĞĞ¢:
{content}

Ğ£Ğ–Ğ• Ğ˜Ğ—Ğ’Ğ•Ğ¡Ğ¢ĞĞ«Ğ• Ğ¡ĞĞ‘Ğ«Ğ¢Ğ˜Ğ¯:
{existing_events}

---

Ğ’ĞµÑ€Ğ½Ğ¸ JSON-Ğ¼Ğ°ÑÑĞ¸Ğ² ĞĞĞ’Ğ«Ğ¥ ÑĞ¾Ğ±Ñ‹Ñ‚Ğ¸Ğ¹ (ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ñ… ĞµÑ‰Ñ‘ Ğ½ĞµÑ‚ Ğ² ÑĞ¿Ğ¸ÑĞºĞµ):
[
  {{"date": "2024-01-15", "event": "hired", "details": "ĞĞ°Ğ½ÑÑ‚ Ğ² Ğ¾Ñ‚Ğ´ĞµĞ» Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸"}},
  {{"date": "2024-03-20", "event": "promotion", "details": "ĞŸĞ¾Ğ²Ñ‹ÑˆĞµĞ½ Ğ´Ğ¾ Senior"}},
]

Ğ¢Ğ¸Ğ¿Ñ‹ ÑĞ¾Ğ±Ñ‹Ñ‚Ğ¸Ğ¹: hired, fired, promotion, demotion, transfer, warning, achievement, meeting, offer, rejection, interview, onboarding, offboarding, other

Ğ•ÑĞ»Ğ¸ Ğ½Ğ¾Ğ²Ñ‹Ñ… ÑĞ¾Ğ±Ñ‹Ñ‚Ğ¸Ğ¹ Ğ½ĞµÑ‚ â€” Ğ²ĞµÑ€Ğ½Ğ¸ Ğ¿ÑƒÑÑ‚Ğ¾Ğ¹ Ğ¼Ğ°ÑÑĞ¸Ğ² []
Ğ’ĞµÑ€Ğ½Ğ¸ Ğ¢ĞĞ›Ğ¬ĞšĞ JSON, Ğ±ĞµĞ· Ğ¿Ğ¾ÑÑĞ½ĞµĞ½Ğ¸Ğ¹."""


class EntityMemoryService:
    """Service for managing entity long-term AI memory."""

    def __init__(self):
        self._client: Optional[anthropic.AsyncAnthropic] = None
        self.model = "claude-sonnet-4-20250514"

    @property
    def client(self) -> anthropic.AsyncAnthropic:
        if self._client is None:
            self._client = anthropic.AsyncAnthropic(api_key=settings.ANTHROPIC_API_KEY)
        return self._client

    def should_update_summary(self, entity, new_content_length: int = 0) -> bool:
        """Check if entity summary should be updated."""
        # No summary yet - definitely update
        if not entity.ai_summary:
            return new_content_length >= MIN_NEW_CONTENT_LENGTH

        # Summary is old - update
        if entity.ai_summary_updated_at:
            age = datetime.utcnow() - entity.ai_summary_updated_at
            if age > SUMMARY_UPDATE_INTERVAL:
                return True

        # Significant new content
        return new_content_length >= MIN_NEW_CONTENT_LENGTH * 2

    async def update_summary(
        self,
        entity,
        new_content: str,
        db_session
    ) -> str:
        """Update entity summary with new content."""
        try:
            # Format key events
            key_events_str = ""
            if entity.key_events:
                for event in entity.key_events:
                    key_events_str += f"- {event.get('date', '?')}: {event.get('event', '?')} - {event.get('details', '')}\n"

            prompt = SUMMARY_PROMPT.format(
                current_summary=entity.ai_summary or "ĞĞµÑ‚ Ğ¿Ñ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰ĞµĞ³Ğ¾ Ñ€ĞµĞ·ÑĞ¼Ğµ",
                new_content=new_content[:8000],  # Limit to avoid token overflow
                key_events=key_events_str or "ĞĞµÑ‚ Ğ·Ğ°Ğ¿Ğ¸ÑĞ°Ğ½Ğ½Ñ‹Ñ… ÑĞ¾Ğ±Ñ‹Ñ‚Ğ¸Ğ¹"
            )

            response = await self.client.messages.create(
                model=self.model,
                max_tokens=1000,
                messages=[{"role": "user", "content": prompt}]
            )

            new_summary = response.content[0].text

            # Update entity
            entity.ai_summary = new_summary
            entity.ai_summary_updated_at = datetime.utcnow()
            await db_session.commit()

            logger.info(f"Updated summary for entity {entity.id}")
            return new_summary

        except Exception as e:
            logger.error(f"Failed to update entity summary: {e}")
            return entity.ai_summary or ""

    async def extract_key_events(
        self,
        entity,
        content: str,
        db_session
    ) -> List[Dict[str, Any]]:
        """Extract and add key events from content."""
        try:
            # Format existing events
            existing_str = ""
            if entity.key_events:
                for event in entity.key_events:
                    existing_str += f"- {event.get('date', '?')}: {event.get('event', '?')}\n"

            prompt = KEY_EVENTS_PROMPT.format(
                content=content[:5000],
                existing_events=existing_str or "ĞĞµÑ‚"
            )

            response = await self.client.messages.create(
                model=self.model,
                max_tokens=500,
                messages=[{"role": "user", "content": prompt}]
            )

            # Parse JSON response
            import json
            text = response.content[0].text.strip()
            # Handle markdown code blocks
            if text.startswith("```"):
                text = text.split("```")[1]
                if text.startswith("json"):
                    text = text[4:]
                text = text.strip()

            new_events = json.loads(text)

            if new_events and isinstance(new_events, list):
                # Add new events
                current_events = entity.key_events or []
                current_events.extend(new_events)

                # Sort by date
                current_events.sort(key=lambda x: x.get("date", "9999"))

                entity.key_events = current_events
                await db_session.commit()

                logger.info(f"Added {len(new_events)} key events for entity {entity.id}")
                return new_events

            return []

        except Exception as e:
            logger.error(f"Failed to extract key events: {e}")
            return []

    def build_memory_context(self, entity) -> str:
        """Build memory context for AI prompts."""
        parts = []

        # Add summary if exists
        if entity.ai_summary:
            parts.append(f"## ğŸ“‹ Ğ ĞµĞ·ÑĞ¼Ğµ ĞºĞ¾Ğ½Ñ‚Ğ°ĞºÑ‚Ğ°\n{entity.ai_summary}")

        # Add key events if exist
        if entity.key_events:
            events_str = "## ğŸ“… ĞšĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ ÑĞ¾Ğ±Ñ‹Ñ‚Ğ¸Ñ\n"
            for event in entity.key_events[-10:]:  # Last 10 events
                emoji = {
                    "hired": "âœ…",
                    "fired": "âŒ",
                    "promotion": "â¬†ï¸",
                    "demotion": "â¬‡ï¸",
                    "transfer": "ğŸ”„",
                    "warning": "âš ï¸",
                    "achievement": "ğŸ†",
                    "meeting": "ğŸ“…",
                    "offer": "ğŸ“",
                    "rejection": "ğŸš«",
                    "interview": "ğŸ¤",
                }.get(event.get("event", ""), "ğŸ“Œ")

                events_str += f"- {event.get('date', '?')} {emoji} {event.get('details', event.get('event', ''))}\n"

            parts.append(events_str)

        return "\n\n".join(parts) if parts else ""


# Singleton instance
entity_memory_service = EntityMemoryService()
